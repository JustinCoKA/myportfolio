export type ProjectItem = {
  title: string
  subtitle: string
  description: string
  detailedDescription?: string
  role?: string
  problemStatement?: string
  solution?: string
  impact?: string
  learnings?: string
  images?: string[]
  tech: string[]
  link: string | null
  github: string | null
  slug: string | null
}

export const projects: ProjectItem[] = [
  {
    title: "UrSaviour ‚Äì Full Stack Software Project (AWS & Python)",
    subtitle: "AI-Supported Grocery Discount Intelligence Platform",
    description:
      "Full-stack application to track weekly supermarket discounts with watchlist and alert features. Architected serverless ETL pipeline on AWS using Lambda, S3, and RDS to process unstructured PDF data.",
    detailedDescription: `üìå Project Overview (Final)

UrSaviour is a law-compliant, AI-assisted grocery discount tracking platform designed to help Australian consumers‚Äîparticularly international students‚Äîmake smarter purchasing decisions amid rising living costs.

Instead of relying on prohibited web scraping or restricted supermarket APIs, UrSaviour introduces an ethically simulated data ecosystem that mirrors real-world grocery discount workflows. The system automatically generates weekly promotional PDFs, ingests them through a serverless AWS ETL pipeline, and delivers personalized discount insights through watchlists and an AI assistant.

This project was delivered as a full-stack, production-style capstone, emphasizing scalability, data governance, automation, and real-world cloud architecture.`,
    role: `üë§ Role & Contribution

**Team Leader ¬∑ Data Engineering ¬∑ Full-Stack Developer**

‚Ä¢ Designed the end-to-end ETL architecture
‚Ä¢ Implemented PDF generation & ingestion workflow
‚Ä¢ Built backend APIs for product pricing & comparison
‚Ä¢ Led system integration, testing, and troubleshooting
‚Ä¢ Coordinated technical direction across a 4-member team`,
    problemStatement: `üß† Problem Statement (Refined)

Australian supermarkets tightly restrict automated data access:
‚Ä¢ Woolworths API ‚Üí approval required
‚Ä¢ Coles ‚Üí no public API
‚Ä¢ Web scraping ‚Üí violates ToS & copyright

**As a result:**
‚Ä¢ Users manually check multiple apps weekly
‚Ä¢ International students struggle to understand discount cycles
‚Ä¢ Existing tools face legal, sustainability, and reliability risks

**Key Challenge:**
How can we design a scalable, realistic grocery discount platform without scraping or real retailer data, while still delivering real value?`,
    solution: `üí° Solution Architecture (Final Implementation)

**1Ô∏è‚É£ Ethical Data Simulation & PDF Generation**
‚Ä¢ Manually curated foundational grocery dataset (SSOT)
‚Ä¢ Python scripts apply randomized discount logic (10%, 30%, Half-Price)
‚Ä¢ ReportLab generates realistic weekly promotional PDFs
‚Ä¢ PDFs stored in AWS S3 (ETL watch bucket)
‚úî Ensures legal compliance | ‚úî Enables continuous testing & automation | ‚úî Mirrors real supermarket workflows

**2Ô∏è‚É£ Serverless ETL Pipeline (AWS)**
‚Ä¢ S3 Event Trigger detects new PDF uploads
‚Ä¢ AWS Lambda executes Extract ‚Üí Transform ‚Üí Load
‚Ä¢ Data parsed, validated, standardized
‚Ä¢ Loaded into MySQL (AWS RDS)
‚Ä¢ ETL logging: etlJobs ‚Üí job-level tracking | etlJobLogs ‚Üí step-by-step diagnostics
‚úî Fully automated | ‚úî Scalable & cost-efficient | ‚úî Production-grade observability

**3Ô∏è‚É£ Product Comparison Engine**
‚Ä¢ Unified product catalog with multi-store pricing
‚Ä¢ Search, filter, and sorting APIs
‚Ä¢ Near-real-time reflection of ETL updates on frontend
‚úî Accurate price comparison | ‚úî Clean REST API design | ‚úî Optimized for low latency

**4Ô∏è‚É£ Personalized Watchlist & Alerts**
‚Ä¢ Users track favorite products
‚Ä¢ Background scheduler compares new ETL data
‚Ä¢ One-alert-per-discount-cycle logic
‚Ä¢ Email & UI notifications
‚úî Noise-free alerts | ‚úî User-controlled notifications | ‚úî Aggregated trend insights

**5Ô∏è‚É£ AI-Powered Shopping Assistant**
‚Ä¢ OpenAI GPT integrated with internal product & pricing data
‚Ä¢ Context-aware answers (not generic chatbot replies)
‚Ä¢ Graceful fallback when AI unavailable
‚úî Improves engagement | ‚úî Reduces user friction | ‚úî Demonstrates real AI-data integration

**6Ô∏è‚É£ Admin Dashboard & System Control**
‚Ä¢ ETL monitoring (success / failure / logs)
‚Ä¢ User account management
‚Ä¢ Product & pricing overrides
‚Ä¢ Secure JWT-based admin access
‚úî Operational visibility | ‚úî Real-world DevOps mindset | ‚úî Audit-friendly design`,
    impact: `üìà Measurable Impact

‚Ä¢ Automated weekly generation & ingestion of 50+ discount items
‚Ä¢ End-to-end ETL execution with full logging & monitoring
‚Ä¢ Zero reliance on scraping or external retailer APIs
‚Ä¢ Fully functional AI-assisted shopping workflow
‚Ä¢ Production-ready system suitable for real data replacement`,
    learnings: `üß™ Real-World Engineering Learnings

‚Ä¢ Designing ethical data pipelines under legal constraints
‚Ä¢ Debugging event-driven systems (S3 ‚Üí Lambda ‚Üí RDS)
‚Ä¢ Handling ETL failures, retries, and observability
‚Ä¢ Balancing realism vs. simulation in data engineering
‚Ä¢ Leading cross-functional collaboration in a capstone environment

üöÄ Why This Project Matters

UrSaviour is not just a student project‚Äîit demonstrates:
‚Ä¢ Cloud-native data engineering
‚Ä¢ Legal-aware system design
‚Ä¢ AI + ETL integration
‚Ä¢ Production-style architecture & documentation

It forms a strong foundation for:
‚Ä¢ Data Engineer roles
‚Ä¢ Cloud / Backend internships
‚Ä¢ AI-driven platform development
‚Ä¢ Real-world system scaling`,
    images: ["/ursaviour-overview.png"],
    tech: ["Python", "FastAPI", "MySQL", "AWS S3", "AWS Lambda", "AWS RDS", "OpenAI API", "ETL", "Docker"],
    link: "https://www.linkedin.com/posts/dataausjustin_aws-dataengineering-python-activity-7396148194671374336-ane1?utm_source=share&utm_medium=member_desktop&rcm=ACoAAEdTT8oBva1fwa9zicx0eKNHiP7o9gSA43oYzX6Z1V6PmU6K3JHcXoXKX4Yz9h8W_gj6nE5GJg0bV0bG1R4BA3E7VbXoGg",
    github: "https://github.com/JustinCoKA/UrSaviour-Project",
    slug: "ursaviour",
  },
  {
    title: "Cancer Data ETL",
    subtitle: "Healthcare Data Analysis",
    description:
      "Analyzed 1.7M cancer records with Python and SQL, identifying tumor patterns and survival rates. Built ETL pipeline to normalize public cancer datasets into PostgreSQL with schema constraints.",
    tech: ["Python", "Pandas", "PostgreSQL", "ETL", "Jupyter", "Data Analysis"],
    link: null,
    github: "https://github.com/JustinCoKA/ProjectCancerData",
    slug: "cancer-data-etl",
  },
  {
    title: "Cloud Data Warehouse",
    subtitle: "AWS Redshift Implementation",
    description:
      "Built scalable data warehouse on Amazon Redshift for music streaming startup. Developed Python ETL pipeline using Infrastructure as Code for data integrity and improved query performance with star schema.",
    tech: ["Python", "AWS Redshift", "AWS S3", "IAM", "SQL", "ETL", "IaC"],
    link: null,
    github: null,
    slug: null,
  },
  {
    title: "Data Modeling with Cassandra",
    subtitle: "NoSQL Database Design",
    description:
      "Designed and built Python-based ETL pipeline to process user activity data from CSV files. Created query-optimized Apache Cassandra database for music streaming analytics.",
    tech: ["Python", "Apache Cassandra", "NoSQL", "ETL", "Data Modeling"],
    link: null,
    github: null,
    slug: null,
  },
]
